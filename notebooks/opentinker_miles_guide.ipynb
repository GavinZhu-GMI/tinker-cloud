{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenTinker-Miles: Build, Deploy & Test Guide\n",
    "\n",
    "This notebook walks through the complete workflow for building, deploying, and testing the OpenTinker-Miles training API.\n",
    "\n",
    "## Contents\n",
    "1. [Build Docker Image](#1-build-docker-image)\n",
    "2. [Start Container](#2-start-container)\n",
    "3. [Health Check & Service Status](#3-health-check--service-status)\n",
    "4. [Model Creation Test](#4-model-creation-test)\n",
    "5. [View Logs & Ray Status](#5-view-logs--ray-status)\n",
    "6. [Cleanup](#6-cleanup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "from IPython.display import display, Markdown, HTML\n",
    "\n",
    "# Configuration\n",
    "IMAGE_NAME = \"us-west1-docker.pkg.dev/devv-404803/gmi-test-repo/opentinker-miles:latest\"\n",
    "CONTAINER_NAME = \"opentinker-miles-test\"\n",
    "DATA_MOUNT = \"/mnt/slime-data-tinker\"  # Host path with pre-downloaded models/datasets\n",
    "SHM_SIZE = \"16g\"\n",
    "\n",
    "# Port mappings (host:container)\n",
    "API_PORT = 8001        # Training API\n",
    "RAY_DASHBOARD_PORT = 8266  # Ray Dashboard\n",
    "RAY_CLIENT_PORT = 10002    # Ray Client\n",
    "\n",
    "# API Configuration\n",
    "GMI_BASE_URL = f\"http://localhost:{API_PORT}\"\n",
    "GMI_API_KEY = \"slime-dev-key\"\n",
    "MODEL_PATH = \"/data/models/Qwen2.5-0.5B-Instruct_torch_dist\"\n",
    "\n",
    "print(f\"Image: {IMAGE_NAME}\")\n",
    "print(f\"Container: {CONTAINER_NAME}\")\n",
    "print(f\"API URL: {GMI_BASE_URL}\")\n",
    "print(f\"Data Mount: {DATA_MOUNT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cmd(cmd, check=True, capture=True):\n",
    "    \"\"\"Run a shell command and return output\"\"\"\n",
    "    result = subprocess.run(cmd, shell=True, capture_output=capture, text=True)\n",
    "    if capture:\n",
    "        if result.returncode != 0 and check:\n",
    "            print(f\"Error: {result.stderr}\")\n",
    "        return result.stdout.strip(), result.stderr.strip(), result.returncode\n",
    "    return None, None, result.returncode\n",
    "\n",
    "def docker_exec(cmd):\n",
    "    \"\"\"Execute command inside the container\"\"\"\n",
    "    return run_cmd(f\"docker exec {CONTAINER_NAME} {cmd}\")\n",
    "\n",
    "def wait_for_api(timeout=60):\n",
    "    \"\"\"Wait for API to be ready\"\"\"\n",
    "    start = time.time()\n",
    "    while time.time() - start < timeout:\n",
    "        try:\n",
    "            resp = requests.get(f\"{GMI_BASE_URL}/health\", timeout=5)\n",
    "            if resp.status_code == 200:\n",
    "                return True\n",
    "        except:\n",
    "            pass\n",
    "        time.sleep(2)\n",
    "    return False\n",
    "\n",
    "def poll_future(request_id, timeout=180):\n",
    "    \"\"\"Poll for async operation completion\"\"\"\n",
    "    headers = {\"X-API-Key\": GMI_API_KEY, \"Content-Type\": \"application/json\"}\n",
    "    start = time.time()\n",
    "    \n",
    "    while time.time() - start < timeout:\n",
    "        resp = requests.post(\n",
    "            f\"{GMI_BASE_URL}/api/v1/retrieve_future\",\n",
    "            json={\"request_id\": request_id},\n",
    "            headers=headers,\n",
    "            timeout=30\n",
    "        )\n",
    "        \n",
    "        if resp.status_code == 200:\n",
    "            return resp.json()\n",
    "        elif resp.status_code == 408:\n",
    "            time.sleep(2)\n",
    "            continue\n",
    "        else:\n",
    "            raise Exception(f\"Error {resp.status_code}: {resp.text}\")\n",
    "    \n",
    "    raise TimeoutError(f\"Operation timed out after {timeout}s\")\n",
    "\n",
    "print(\"✓ Helper functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Build Docker Image\n",
    "\n",
    "Build the OpenTinker-Miles Docker image using the provided build script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if we're in the right directory\n",
    "import os\n",
    "project_dir = os.path.dirname(os.path.dirname(os.path.abspath(\"__file__\")))\n",
    "print(f\"Project directory: {project_dir}\")\n",
    "\n",
    "# List docker directory contents\n",
    "stdout, stderr, rc = run_cmd(\"ls -la docker/\")\n",
    "print(\"\\nDocker directory contents:\")\n",
    "print(stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the Docker image\n",
    "print(\"Building Docker image...\")\n",
    "print(\"This may take a few minutes if layers are not cached.\\n\")\n",
    "\n",
    "stdout, stderr, rc = run_cmd(\"./docker/build.sh\", check=False)\n",
    "print(stdout)\n",
    "if stderr:\n",
    "    print(f\"\\nStderr:\\n{stderr}\")\n",
    "\n",
    "if rc == 0:\n",
    "    print(\"\\n✓ Docker image built successfully!\")\n",
    "else:\n",
    "    print(f\"\\n✗ Build failed with exit code {rc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the image exists\n",
    "stdout, _, _ = run_cmd(f\"docker images | grep opentinker-miles | head -3\")\n",
    "print(\"Docker images:\")\n",
    "print(stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Start Container\n",
    "\n",
    "Start the container with:\n",
    "- All GPUs (`--gpus all`)\n",
    "- Shared memory for NCCL (`--shm-size=16g`)\n",
    "- Data volume mount (`-v /mnt/slime-data-tinker:/data`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop and remove existing container if it exists\n",
    "print(\"Cleaning up existing container...\")\n",
    "run_cmd(f\"docker stop {CONTAINER_NAME} 2>/dev/null\", check=False)\n",
    "run_cmd(f\"docker rm {CONTAINER_NAME} 2>/dev/null\", check=False)\n",
    "print(\"✓ Cleanup done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the container\n",
    "docker_run_cmd = f\"\"\"\n",
    "docker run -d \\\n",
    "  --name {CONTAINER_NAME} \\\n",
    "  --gpus all \\\n",
    "  --shm-size={SHM_SIZE} \\\n",
    "  -v {DATA_MOUNT}:/data \\\n",
    "  -p {API_PORT}:8000 \\\n",
    "  -p {RAY_DASHBOARD_PORT}:8265 \\\n",
    "  -p {RAY_CLIENT_PORT}:10001 \\\n",
    "  -e LOG_LEVEL=INFO \\\n",
    "  {IMAGE_NAME}\n",
    "\"\"\".strip()\n",
    "\n",
    "print(\"Starting container with command:\")\n",
    "print(docker_run_cmd)\n",
    "print()\n",
    "\n",
    "stdout, stderr, rc = run_cmd(docker_run_cmd)\n",
    "if rc == 0:\n",
    "    print(f\"✓ Container started: {stdout[:12]}...\")\n",
    "else:\n",
    "    print(f\"✗ Failed to start container: {stderr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for API to be ready\n",
    "print(\"Waiting for API to be ready...\")\n",
    "if wait_for_api(timeout=60):\n",
    "    print(\"✓ API is ready!\")\n",
    "else:\n",
    "    print(\"✗ API failed to start within timeout\")\n",
    "    print(\"\\nChecking container logs:\")\n",
    "    stdout, _, _ = run_cmd(f\"docker logs {CONTAINER_NAME} --tail 30\")\n",
    "    print(stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Health Check & Service Status\n",
    "\n",
    "Verify the service is running correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Health check\n",
    "print(\"=\" * 60)\n",
    "print(\"HEALTH CHECK\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    resp = requests.get(f\"{GMI_BASE_URL}/health\", timeout=10)\n",
    "    health = resp.json()\n",
    "    \n",
    "    print(f\"Status:          {health.get('status')}\")\n",
    "    print(f\"Version:         {health.get('version')}\")\n",
    "    print(f\"Ray Initialized: {health.get('ray_initialized')}\")\n",
    "    print(f\"Active Clients:  {health.get('active_training_clients')}\")\n",
    "    print(f\"Model IDs:       {health.get('model_ids', [])}\")\n",
    "    print(f\"Futures Count:   {health.get('futures_count')}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    if health.get('status') == 'healthy':\n",
    "        print(\"✓ Service is healthy!\")\n",
    "    else:\n",
    "        print(\"⚠ Service may have issues\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"✗ Health check failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check container status\n",
    "print(\"Container Status:\")\n",
    "stdout, _, _ = run_cmd(f\"docker ps --filter name={CONTAINER_NAME} --format 'table {{{{.Names}}}}\\t{{{{.Status}}}}\\t{{{{.Ports}}}}'\")\n",
    "print(stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Model Creation Test\n",
    "\n",
    "Create a training model and verify it's ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model\n",
    "print(\"=\" * 60)\n",
    "print(\"MODEL CREATION TEST\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Base Model: {MODEL_PATH}\")\n",
    "print(f\"LoRA: disabled (rank=0)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "headers = {\"X-API-Key\": GMI_API_KEY, \"Content-Type\": \"application/json\"}\n",
    "\n",
    "try:\n",
    "    # Submit create model request\n",
    "    print(\"\\n[1/3] Submitting create model request...\")\n",
    "    resp = requests.post(\n",
    "        f\"{GMI_BASE_URL}/api/v1/create_model\",\n",
    "        json={\n",
    "            \"base_model\": MODEL_PATH,\n",
    "            \"lora_config\": {\"rank\": 0, \"alpha\": 0}\n",
    "        },\n",
    "        headers=headers,\n",
    "        timeout=30\n",
    "    )\n",
    "    \n",
    "    if resp.status_code != 200:\n",
    "        print(f\"✗ Failed: {resp.status_code} - {resp.text}\")\n",
    "    else:\n",
    "        result = resp.json()\n",
    "        request_id = result[\"request_id\"]\n",
    "        print(f\"✓ Request submitted: {request_id}\")\n",
    "        \n",
    "        # Poll for completion\n",
    "        print(\"\\n[2/3] Waiting for model creation (this may take 1-2 minutes)...\")\n",
    "        result = poll_future(request_id, timeout=180)\n",
    "        \n",
    "        model_id = result.get(\"model_id\")\n",
    "        print(f\"✓ Model created: {model_id}\")\n",
    "        print(f\"  Status: {result.get('status')}\")\n",
    "        \n",
    "        # Verify via health check\n",
    "        print(\"\\n[3/3] Verifying model state...\")\n",
    "        health = requests.get(f\"{GMI_BASE_URL}/health\").json()\n",
    "        print(f\"✓ Active training clients: {health.get('active_training_clients')}\")\n",
    "        print(f\"  Model IDs: {health.get('model_ids', [])}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"✓ MODEL CREATION TEST PASSED!\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"\\n✗ Test failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. View Logs & Ray Status\n",
    "\n",
    "Monitor service logs and Ray cluster status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View container logs (last 50 lines)\n",
    "print(\"=\" * 60)\n",
    "print(\"CONTAINER LOGS (last 50 lines)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "stdout, stderr, _ = run_cmd(f\"docker logs {CONTAINER_NAME} --tail 50 2>&1\")\n",
    "print(stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View Ray cluster status\n",
    "print(\"=\" * 60)\n",
    "print(\"RAY CLUSTER STATUS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "stdout, _, _ = docker_exec(\"ray status\")\n",
    "print(stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List Ray actors\n",
    "print(\"=\" * 60)\n",
    "print(\"RAY ACTORS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "stdout, _, _ = docker_exec(\"ray list actors 2>/dev/null\")\n",
    "print(stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List only ALIVE actors\n",
    "print(\"=\" * 60)\n",
    "print(\"ALIVE RAY ACTORS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "stdout, _, _ = docker_exec(\"ray list actors --filter state=ALIVE 2>/dev/null\")\n",
    "print(stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU status\n",
    "print(\"=\" * 60)\n",
    "print(\"GPU STATUS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "stdout, _, _ = docker_exec(\"nvidia-smi --query-gpu=index,name,memory.used,memory.total,utilization.gpu --format=csv\")\n",
    "print(stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Ray placement groups\n",
    "print(\"=\" * 60)\n",
    "print(\"RAY PLACEMENT GROUPS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "stdout, _, _ = docker_exec(\"ray list placement-groups 2>/dev/null\")\n",
    "print(stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log Viewing Commands\n",
    "\n",
    "Use these commands to view logs in different ways:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print useful log commands\n",
    "print(\"Useful commands for viewing logs:\\n\")\n",
    "print(f\"# View all logs\")\n",
    "print(f\"docker logs {CONTAINER_NAME}\")\n",
    "print()\n",
    "print(f\"# View last N lines\")\n",
    "print(f\"docker logs {CONTAINER_NAME} --tail 100\")\n",
    "print()\n",
    "print(f\"# Follow logs in real-time\")\n",
    "print(f\"docker logs {CONTAINER_NAME} -f\")\n",
    "print()\n",
    "print(f\"# View logs with timestamps\")\n",
    "print(f\"docker logs {CONTAINER_NAME} -t\")\n",
    "print()\n",
    "print(f\"# View logs since last 10 minutes\")\n",
    "print(f\"docker logs {CONTAINER_NAME} --since 10m\")\n",
    "print()\n",
    "print(f\"# Combined: last 50 lines with timestamps, follow\")\n",
    "print(f\"docker logs {CONTAINER_NAME} --tail 50 -f -t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Cleanup\n",
    "\n",
    "Clean up models and optionally stop the container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup active models\n",
    "print(\"=\" * 60)\n",
    "print(\"CLEANUP\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "headers = {\"X-API-Key\": GMI_API_KEY, \"Content-Type\": \"application/json\"}\n",
    "\n",
    "# Get active models\n",
    "try:\n",
    "    health = requests.get(f\"{GMI_BASE_URL}/health\", timeout=10).json()\n",
    "    model_ids = health.get(\"model_ids\", [])\n",
    "    \n",
    "    if not model_ids:\n",
    "        print(\"✓ No active models to cleanup\")\n",
    "    else:\n",
    "        print(f\"Found {len(model_ids)} active model(s): {model_ids}\")\n",
    "        \n",
    "        for model_id in model_ids:\n",
    "            print(f\"\\nDeleting model: {model_id}...\")\n",
    "            resp = requests.post(\n",
    "                f\"{GMI_BASE_URL}/api/v1/delete_model\",\n",
    "                json={\"model_id\": model_id},\n",
    "                headers=headers,\n",
    "                timeout=30\n",
    "            )\n",
    "            \n",
    "            if resp.status_code == 200:\n",
    "                result = resp.json()\n",
    "                req_id = result.get(\"request_id\")\n",
    "                if req_id:\n",
    "                    poll_future(req_id, timeout=60)\n",
    "                print(f\"✓ Deleted: {model_id}\")\n",
    "            else:\n",
    "                print(f\"⚠ Delete returned: {resp.status_code}\")\n",
    "        \n",
    "        # Verify cleanup\n",
    "        health = requests.get(f\"{GMI_BASE_URL}/health\", timeout=10).json()\n",
    "        print(f\"\\nActive clients after cleanup: {health.get('active_training_clients')}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"✗ Cleanup error: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"✓ CLEANUP COMPLETE\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Stop the container\n",
    "# Uncomment the following lines to stop and remove the container\n",
    "\n",
    "# print(\"Stopping container...\")\n",
    "# run_cmd(f\"docker stop {CONTAINER_NAME}\")\n",
    "# print(\"✓ Container stopped\")\n",
    "\n",
    "# print(\"Removing container...\")\n",
    "# run_cmd(f\"docker rm {CONTAINER_NAME}\")\n",
    "# print(\"✓ Container removed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restart container (if needed)\n",
    "# Uncomment to restart the container\n",
    "\n",
    "# print(\"Restarting container...\")\n",
    "# run_cmd(f\"docker restart {CONTAINER_NAME}\")\n",
    "# print(\"Waiting for API...\")\n",
    "# if wait_for_api(timeout=60):\n",
    "#     print(\"✓ Container restarted and API is ready!\")\n",
    "# else:\n",
    "#     print(\"✗ API failed to come up after restart\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Quick Reference\n",
    "\n",
    "### Docker Commands\n",
    "```bash\n",
    "# Start container\n",
    "docker run -d --name opentinker-miles-test --gpus all --shm-size=16g \\\n",
    "  -v /mnt/slime-data-tinker:/data \\\n",
    "  -p 8001:8000 -p 8266:8265 -p 10002:10001 \\\n",
    "  us-west1-docker.pkg.dev/devv-404803/gmi-test-repo/opentinker-miles:latest\n",
    "\n",
    "# View logs\n",
    "docker logs opentinker-miles-test --tail 100\n",
    "\n",
    "# Restart container\n",
    "docker restart opentinker-miles-test\n",
    "\n",
    "# Stop and remove\n",
    "docker stop opentinker-miles-test && docker rm opentinker-miles-test\n",
    "```\n",
    "\n",
    "### Ray Commands (inside container)\n",
    "```bash\n",
    "# Check Ray status\n",
    "docker exec opentinker-miles-test ray status\n",
    "\n",
    "# List all actors\n",
    "docker exec opentinker-miles-test ray list actors\n",
    "\n",
    "# List alive actors only\n",
    "docker exec opentinker-miles-test ray list actors --filter state=ALIVE\n",
    "\n",
    "# List placement groups\n",
    "docker exec opentinker-miles-test ray list placement-groups\n",
    "```\n",
    "\n",
    "### API Endpoints\n",
    "- Health: `GET http://localhost:8001/health`\n",
    "- Create Model: `POST http://localhost:8001/api/v1/create_model`\n",
    "- Delete Model: `POST http://localhost:8001/api/v1/delete_model`\n",
    "- Save Weights: `POST http://localhost:8001/api/v1/save_weights`\n",
    "- Retrieve Future: `POST http://localhost:8001/api/v1/retrieve_future`\n",
    "\n",
    "### URLs\n",
    "- Training API: http://localhost:8001\n",
    "- Ray Dashboard: http://localhost:8266\n",
    "- API Docs: http://localhost:8001/docs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
